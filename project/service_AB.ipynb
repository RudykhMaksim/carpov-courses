{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e36d44-e104-413c-9e3c-afc1e645406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from typing import List\n",
    "from catboost import CatBoostClassifier\n",
    "from fastapi import FastAPI\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from schema import PostGet, Response\n",
    "\n",
    "# ==================== КОНФИГУРАЦИЯ A/B ЭКСПЕРИМЕНТА ====================\n",
    "SALT = \"recommender_salt_2025\"  # Соль для хэширования\n",
    "CONTROL_GROUP_RATIO = 0.5  # 50% пользователей в контрольной группе\n",
    "TEST_GROUP_RATIO = 0.5     # 50% пользователей в тестовой группе\n",
    "\n",
    "# ==================== ИНИЦИАЛИЗАЦИЯ ПРИЛОЖЕНИЯ ====================\n",
    "app = FastAPI()\n",
    "\n",
    "def batch_load_sql(query: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загрузка больших объемов данных из PostgreSQL с потоковой обработкой.\n",
    "    \"\"\"\n",
    "    engine = create_engine(\n",
    "        \"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "    conn = engine.connect().execution_options(stream_results=True)\n",
    "    \n",
    "    chunks = []\n",
    "    for chunk_dataframe in pd.read_sql(query, conn, chunksize=200000):\n",
    "        chunks.append(chunk_dataframe)\n",
    "    \n",
    "    conn.close()\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "\n",
    "def get_model_path(model_name: str, path: str) -> str:\n",
    "    \"\"\"\n",
    "    Определение пути к модели в зависимости от окружения и имени модели.\n",
    "    \"\"\"\n",
    "    if os.environ.get(\"IS_LMS\") == \"1\":\n",
    "        return f'/workdir/user_input/{model_name}'\n",
    "    else:\n",
    "        return path\n",
    "\n",
    "\n",
    "def load_models() -> dict:\n",
    "    \"\"\"\n",
    "    Загрузка обеих моделей: контрольной и тестовой.\n",
    "    \"\"\"\n",
    "    # Загрузка контрольной модели (без нейросетей)\n",
    "    model_control_path = get_model_path(\"model_control\", \"recommender_model_v_exp.cbm\")\n",
    "    model_control = CatBoostClassifier()\n",
    "    model_control.load_model(model_control_path)\n",
    "    \n",
    "    # Загрузка тестовой модели (с нейросетями)\n",
    "    model_test_path = get_model_path(\"model_test\", \"recommender_model_v_exp_neural.cbm\")\n",
    "    model_test = CatBoostClassifier()\n",
    "    model_test.load_model(model_test_path)\n",
    "    \n",
    "    return {\n",
    "        'control': model_control,\n",
    "        'test': model_test\n",
    "    }\n",
    "\n",
    "\n",
    "def load_features() -> dict:\n",
    "    \"\"\"\n",
    "    Загрузка всех необходимых данных для рекомендаций.\n",
    "    \"\"\"\n",
    "    # Загрузка информации о лайкнутых постах\n",
    "    liked_posts_query = \"\"\"\n",
    "        SELECT DISTINCT post_id, user_id\n",
    "        FROM feed_data\n",
    "        WHERE action = 'like'\n",
    "    \"\"\"\n",
    "    liked_posts = batch_load_sql(liked_posts_query)\n",
    "\n",
    "    # Загрузка признаков постов для контрольной модели (без нейросетей)\n",
    "    posts_features_control = pd.read_sql(\n",
    "        \"SELECT * FROM k_m_exp_38_post_features_lesson_22\",\n",
    "        con=\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "            \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "\n",
    "    # Загрузка признаков постов для тестовой модели (с нейросетями)\n",
    "    posts_features_test = pd.read_sql(\n",
    "        \"SELECT * FROM k_m_exp_neural_38_post_features_lesson_22\",\n",
    "        con=\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "            \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "\n",
    "    # Загрузка данных пользователей\n",
    "    user_features = pd.read_sql(\n",
    "        \"SELECT * FROM user_data\",\n",
    "        con=\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "            \"postgres.lab.karpov.courses:6432/startml\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'liked_posts': liked_posts,\n",
    "        'posts_features_control': posts_features_control,\n",
    "        'posts_features_test': posts_features_test,\n",
    "        'user_features': user_features\n",
    "    }\n",
    "\n",
    "\n",
    "def get_exp_group(user_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Определение экспериментальной группы пользователя на основе хэша user_id.\n",
    "    \n",
    "    Args:\n",
    "        user_id: ID пользователя\n",
    "        \n",
    "    Returns:\n",
    "        str: 'control' или 'test'\n",
    "    \"\"\"\n",
    "    # Создаем хэш от user_id с солью\n",
    "    hash_str = hashlib.md5(f\"{user_id}_{SALT}\".encode()).hexdigest()\n",
    "    \n",
    "    # Преобразуем хэш в число от 0 до 1\n",
    "    hash_ratio = int(hash_str[:8], 16) / 0xFFFFFFFF\n",
    "    \n",
    "    # Определяем группу на основе заданных пропорций\n",
    "    if hash_ratio < CONTROL_GROUP_RATIO:\n",
    "        return \"control\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "\n",
    "\n",
    "# ==================== ЗАГРУЗКА МОДЕЛЕЙ И ДАННЫХ ПРИ СТАРТЕ ====================\n",
    "print(\"Загрузка моделей...\")\n",
    "models = load_models()\n",
    "model_control = models['control']\n",
    "model_test = models['test']\n",
    "\n",
    "print(\"Загрузка признаков...\")\n",
    "features = load_features()\n",
    "\n",
    "# Определяем ожидаемые колонки для каждой модели\n",
    "EXPECTED_FEATURES_CONTROL = [\n",
    "    'topic', 'TotalTfIdf', 'MaxTfIdf', 'MeanTfIdf', 'TextCluster',\n",
    "    'DistanceToCluster_1', 'DistanceToCluster_2', 'DistanceToCluster_3',\n",
    "    'DistanceToCluster_4', 'DistanceToCluster_5', 'DistanceToCluster_6', \n",
    "    'DistanceToCluster_7', 'DistanceToCluster_8', 'DistanceToCluster_9',\n",
    "    'DistanceToCluster_10', 'DistanceToCluster_11', 'DistanceToCluster_12',\n",
    "    'DistanceToCluster_13', 'DistanceToCluster_14', 'DistanceToCluster_15',\n",
    "    'gender', 'age', 'country', 'city', 'exp_group', 'os', 'source', 'hour', 'month'\n",
    "]\n",
    "\n",
    "EXPECTED_FEATURES_TEST = [\n",
    "    'topic', 'EmbeddingNorm', 'EmbeddingMean', 'EmbeddingStd', 'TextCluster',\n",
    "    'DistanceToCluster_1', 'DistanceToCluster_2', 'DistanceToCluster_3',\n",
    "    'DistanceToCluster_4', 'DistanceToCluster_5', 'DistanceToCluster_6', \n",
    "    'DistanceToCluster_7', 'DistanceToCluster_8', 'DistanceToCluster_9',\n",
    "    'DistanceToCluster_10', 'DistanceToCluster_11', 'DistanceToCluster_12',\n",
    "    'DistanceToCluster_13', 'DistanceToCluster_14', 'DistanceToCluster_15',\n",
    "    'PC_1', 'PC_2', 'PC_3', 'PC_4', 'PC_5', 'PC_6', 'PC_7', 'PC_8', 'PC_9', 'PC_10',\n",
    "    'PC_11', 'PC_12', 'PC_13', 'PC_14', 'PC_15', 'PC_16', 'PC_17', 'PC_18', 'PC_19', 'PC_20',\n",
    "    'gender', 'age', 'country', 'city', 'exp_group', 'os', 'source', 'hour', 'month'\n",
    "]\n",
    "\n",
    "# Категориальные признаки (одинаковые для обеих моделей)\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'topic', 'TextCluster', 'gender', 'country', \n",
    "    'city', 'exp_group', 'hour', 'month', 'os', 'source'\n",
    "]\n",
    "\n",
    "\n",
    "def get_recommendations_control(user_id: int, time: datetime, limit: int) -> List[PostGet]:\n",
    "    \"\"\"\n",
    "    Генерация рекомендаций с использованием контрольной модели (без нейросетей).\n",
    "    \"\"\"\n",
    "    print(f\"Применяем контрольную модель для пользователя {user_id}\")\n",
    "    \n",
    "    # Получение признаков пользователя\n",
    "    user_data = features['user_features'].loc[features['user_features'].user_id == user_id]\n",
    "    if user_data.empty:\n",
    "        print(f\"Пользователь {user_id} не найден\")\n",
    "        return []\n",
    "    \n",
    "    user_data = user_data.drop('user_id', axis=1)\n",
    "\n",
    "    # Поиск колонки с идентификатором поста\n",
    "    post_id_column = None\n",
    "    possible_post_id_names = ['post_id', 'id', 'post_id', 'postid']\n",
    "    \n",
    "    for col_name in possible_post_id_names:\n",
    "        if col_name in features['posts_features_control'].columns:\n",
    "            post_id_column = col_name\n",
    "            break\n",
    "    \n",
    "    if post_id_column is None:\n",
    "        print(\"Ошибка: не найдена колонка с идентификатором поста в контрольных данных\")\n",
    "        return []\n",
    "\n",
    "    # Подготовка признаков постов для контрольной модели\n",
    "    available_features = [col for col in EXPECTED_FEATURES_CONTROL if col in features['posts_features_control'].columns]\n",
    "    \n",
    "    posts_data = features['posts_features_control'][available_features].copy()\n",
    "    posts_data[post_id_column] = features['posts_features_control'][post_id_column]\n",
    "    \n",
    "    # Данные для ответа\n",
    "    text_column = 'text'\n",
    "    topic_column = 'topic'\n",
    "    post_content = features['posts_features_control'][[post_id_column, text_column, topic_column]].copy()\n",
    "\n",
    "    # Создание объединенного датафрейма\n",
    "    user_features_dict = dict(zip(user_data.columns, user_data.values[0]))\n",
    "    user_posts_data = posts_data.assign(**user_features_dict)\n",
    "    user_posts_data = user_posts_data.set_index(post_id_column)\n",
    "\n",
    "    # Добавление временных признаков\n",
    "    user_posts_data['hour'] = time.hour\n",
    "    user_posts_data['month'] = time.month\n",
    "\n",
    "    # Предсказание\n",
    "    try:\n",
    "        predictions = model_control.predict_proba(user_posts_data)[:, 1]\n",
    "        user_posts_data['predicts'] = predictions\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при предсказании контрольной моделью: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Фильтрация лайкнутых постов\n",
    "    user_liked_posts = features['liked_posts'][features['liked_posts'].user_id == user_id][post_id_column].values\n",
    "    filtered_posts = user_posts_data[~user_posts_data.index.isin(user_liked_posts)]\n",
    "\n",
    "    # Выбор топ-N постов\n",
    "    recommended_post_ids = filtered_posts.sort_values('predicts')[-limit:].index\n",
    "\n",
    "    # Формирование ответа\n",
    "    recommendations = []\n",
    "    for post_id in recommended_post_ids:\n",
    "        post_info = post_content[post_content[post_id_column] == post_id]\n",
    "        if not post_info.empty:\n",
    "            recommendations.append(\n",
    "                PostGet(**{\n",
    "                    \"id\": int(post_id),\n",
    "                    \"text\": post_info[text_column].values[0],\n",
    "                    \"topic\": post_info[topic_column].values[0]\n",
    "                })\n",
    "            )\n",
    "    \n",
    "    print(f\"Контрольная модель сгенерировала {len(recommendations)} рекомендаций для пользователя {user_id}\")\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def get_recommendations_test(user_id: int, time: datetime, limit: int) -> List[PostGet]:\n",
    "    \"\"\"\n",
    "    Генерация рекомендаций с использованием тестовой модели (с нейросетями).\n",
    "    \"\"\"\n",
    "    print(f\"Применяем тестовую модель для пользователя {user_id}\")\n",
    "    \n",
    "    # Получение признаков пользователя\n",
    "    user_data = features['user_features'].loc[features['user_features'].user_id == user_id]\n",
    "    if user_data.empty:\n",
    "        print(f\"Пользователь {user_id} не найден\")\n",
    "        return []\n",
    "    \n",
    "    user_data = user_data.drop('user_id', axis=1)\n",
    "\n",
    "    # Поиск колонки с идентификатором поста\n",
    "    post_id_column = None\n",
    "    possible_post_id_names = ['post_id', 'id', 'post_id', 'postid']\n",
    "    \n",
    "    for col_name in possible_post_id_names:\n",
    "        if col_name in features['posts_features_test'].columns:\n",
    "            post_id_column = col_name\n",
    "            break\n",
    "    \n",
    "    if post_id_column is None:\n",
    "        print(\"Ошибка: не найдена колонка с идентификатором поста в тестовых данных\")\n",
    "        return []\n",
    "\n",
    "    # Подготовка признаков постов для тестовой модели\n",
    "    available_features = [col for col in EXPECTED_FEATURES_TEST if col in features['posts_features_test'].columns]\n",
    "    \n",
    "    posts_data = features['posts_features_test'][available_features].copy()\n",
    "    posts_data[post_id_column] = features['posts_features_test'][post_id_column]\n",
    "    \n",
    "    # Данные для ответа\n",
    "    text_column = 'text'\n",
    "    topic_column = 'topic'\n",
    "    post_content = features['posts_features_test'][[post_id_column, text_column, topic_column]].copy()\n",
    "\n",
    "    # Создание объединенного датафрейма\n",
    "    user_features_dict = dict(zip(user_data.columns, user_data.values[0]))\n",
    "    user_posts_data = posts_data.assign(**user_features_dict)\n",
    "    user_posts_data = user_posts_data.set_index(post_id_column)\n",
    "\n",
    "    # Добавление временных признаков\n",
    "    user_posts_data['hour'] = time.hour\n",
    "    user_posts_data['month'] = time.month\n",
    "\n",
    "    # Предсказание\n",
    "    try:\n",
    "        predictions = model_test.predict_proba(user_posts_data)[:, 1]\n",
    "        user_posts_data['predicts'] = predictions\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при предсказании тестовой моделью: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Фильтрация лайкнутых постов\n",
    "    user_liked_posts = features['liked_posts'][features['liked_posts'].user_id == user_id][post_id_column].values\n",
    "    filtered_posts = user_posts_data[~user_posts_data.index.isin(user_liked_posts)]\n",
    "\n",
    "    # Выбор топ-N постов\n",
    "    recommended_post_ids = filtered_posts.sort_values('predicts')[-limit:].index\n",
    "\n",
    "    # Формирование ответа\n",
    "    recommendations = []\n",
    "    for post_id in recommended_post_ids:\n",
    "        post_info = post_content[post_content[post_id_column] == post_id]\n",
    "        if not post_info.empty:\n",
    "            recommendations.append(\n",
    "                PostGet(**{\n",
    "                    \"id\": int(post_id),\n",
    "                    \"text\": post_info[text_column].values[0],\n",
    "                    \"topic\": post_info[topic_column].values[0]\n",
    "                })\n",
    "            )\n",
    "    \n",
    "    print(f\"Тестовая модель сгенерировала {len(recommendations)} рекомендаций для пользователя {user_id}\")\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def get_recommended_feed(user_id: int, time: datetime, limit: int) -> Response:\n",
    "    \"\"\"\n",
    "    Основная функция для генерации рекомендаций с A/B тестированием.\n",
    "    \n",
    "    Returns:\n",
    "        Response: Объект с группой и рекомендациями\n",
    "    \"\"\"\n",
    "    # Определяем группу пользователя\n",
    "    exp_group = get_exp_group(user_id)\n",
    "    print(f\"Пользователь {user_id} определен в группу: {exp_group}\")\n",
    "    \n",
    "    # Выбираем соответствующую модель\n",
    "    if exp_group == \"control\":\n",
    "        recommendations = get_recommendations_control(user_id, time, limit)\n",
    "    elif exp_group == \"test\":\n",
    "        recommendations = get_recommendations_test(user_id, time, limit)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестная группа: {exp_group}\")\n",
    "    \n",
    "    # Возвращаем ответ с указанием группы\n",
    "    return Response(\n",
    "        exp_group=exp_group,\n",
    "        recommendations=recommendations\n",
    "    )\n",
    "\n",
    "\n",
    "# ==================== API ENDPOINT ====================\n",
    "@app.get(\"/post/recommendations/\", response_model=Response)\n",
    "def recommended_posts(\n",
    "    id: int, \n",
    "    time: datetime, \n",
    "    limit: int = 10\n",
    ") -> Response:\n",
    "    \"\"\"\n",
    "    API endpoint для получения рекомендаций постов с A/B тестированием.\n",
    "    \n",
    "    Returns:\n",
    "        Response: Объект с экспериментальной группой и рекомендациями\n",
    "    \"\"\"\n",
    "    return get_recommended_feed(id, time, limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
